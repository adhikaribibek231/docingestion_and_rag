Absolutely â€” here is a **clean, polished, company-neutral README.md** you can use for:

âœ” Your GitHub
âœ” Your resume portfolio
âœ” Technical interviews
âœ” Showcasing backend, RAG, and LLM engineering skills

No Palm Mind references.
Professional, simple, clean.

---

# ğŸ“š Document Ingestion + RAG Backend

*A modular backend that ingests documents, stores embeddings, answers questions using a custom RAG pipeline, supports multi-turn chat memory, and performs LLM-powered interview booking.*

Built with **FastAPI**, **Qdrant**, **Redis**, **SQLite**, and **DeepSeek-R1:1.5B via Ollama**.

---

# ğŸŒŸ Features

### âœ” Document Ingestion API

Upload PDFs or TXT files â†’ extract text â†’ chunk â†’ embed â†’ store in Qdrant.

### âœ” Conversational RAG API

Custom retrieval-augmented generation pipeline built without FAISS, Chroma, or LangChain RetrievalQAChain.

### âœ” Multi-turn Chat Memory

Each conversation uses a session ID, and history is stored in Redis.

### âœ” LLM-Powered Booking System

Extracts name, email, date, and time from natural language and stores bookings in SQLite.

### âœ” Clean, Modular Architecture

Services for embeddings, chunking, vector store, LLM access, intent detection, booking, etc.

---

# ğŸ§© Tech Stack

**Backend Framework:** FastAPI
**LLM:** DeepSeek-R1:1.5B via Ollama
**Embeddings:** MiniLM (HuggingFace)
**Vector Store:** Qdrant
**Memory:** Redis
**Database:** SQLite (SQLModel ORM)

All components run locally â€” no cloud services required.

---

# ğŸ› ï¸ 1. First-Time Setup

### Clone the repository

```
git clone https://github.com/adhikaribibek231/docingestion_and_rag.git
cd docingestion_and_rag/backend
```

### Create & activate a Python virtual environment

```
python -m venv .venv
.\.venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

### Install Ollama + DeepSeek-R1 model

```
ollama pull deepseek-r1:1.5b
```

### Install Docker Desktop

Required for Qdrant and Redis.

---

# ğŸ” 2. How to Run (Every Session)

Start each service in its own terminal window.

### Terminal 1 â€” Qdrant (Vector DB)

```
docker run -p 6333:6333 qdrant/qdrant
```

### Terminal 2 â€” Redis (Chat Memory)

```
docker run -p 6379:6379 redis
```

### Terminal 3 â€” Ollama Server

```
ollama serve
```

### Terminal 4 â€” DeepSeek Model

```
ollama run deepseek-r1:1.5b
```

### Terminal 5 â€” FastAPI Server

```
cd docingestion_and_rag/backend
.\.venv\Scripts\activate
uvicorn app.main:app --reload
```

API documentation:
ğŸ‘‰ [http://localhost:8000/docs](http://localhost:8000/docs)

---

# ğŸ§ª 3. API Usage

## Health Check

```
GET /health
```

---

## A) Ingest a document

```
POST /documents/ingest?chunk_strategy=fixed
```

Supports:
â€¢ PDF
â€¢ TXT

Example:

```
curl -X POST "http://localhost:8000/documents/ingest?chunk_strategy=fixed" ^
-F "file=@C:/path/to/document.txt"
```

Response:

```
{
  "document_id": "abc123",
  "num_chunks": 5,
  "chunk_strategy": "fixed"
}
```

---

## B) Ask a question (RAG)

```
POST /chat/message
```

Example:

```
{
  "session_id": "demo1",
  "query": "What does the document say?",
  "document_id": "abc123"
}
```

The backend:
â€¢ retrieves relevant chunks from Qdrant
â€¢ builds a custom prompt
â€¢ generates answers using DeepSeek-R1
â€¢ maintains chat history in Redis

---

## C) Book an interview (LLM extraction)

```
{
  "session_id": "book1",
  "query": "Book an interview tomorrow at 10am for Alex. Email alex@example.com"
}
```

Response:

```
{
  "answer": "Your interview with Alex (alex@example.com) is booked on 2025-11-19 at 10:00.",
  "session_id": "book1"
}
```

Booking is saved in SQLite.

---

# ğŸ“‚ 4. Data Storage

**SQLite (`backend/PMrag.db`)**
Stores:
â€¢ Document metadata
â€¢ Bookings

**Qdrant** ([http://localhost:6333](http://localhost:6333))
Stores:
â€¢ Embeddings
â€¢ Chunk metadata

**Redis**
Stores:
â€¢ Chat history
â€¢ Booking drafts

---

# ğŸ” 5. Example Queries to Try

### Document comprehension

â€œSummarize this document.â€
â€œWhat are the main points?â€
â€œWhat does the last section mean?â€

### Follow-up questions (same session_id)

â€œExplain that more simply.â€
â€œGive me an example.â€

### Booking

â€œSchedule an interview at 3pm tomorrow.â€
â€œItâ€™s for Maya, email [maya@example.com](mailto:maya@example.com).â€

---

---

# âœ… 6. Completed Capabilities

| Capability                | Status |
| ------------------------- | ------ |
| PDF/TXT ingestion         | âœ”      |
| Text extraction           | âœ”      |
| Chunking (fixed + window) | âœ”      |
| Embeddings generation     | âœ”      |
| Qdrant storage            | âœ”      |
| Custom RAG pipeline       | âœ”      |
| Redis multi-turn memory   | âœ”      |
| LLM-powered booking       | âœ”      |
| SQLite persistence        | âœ”      |
| No Chroma / No FAISS      | âœ”      |
| No RetrievalQAChain       | âœ”      |

---

